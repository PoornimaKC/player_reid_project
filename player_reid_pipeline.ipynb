{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274dc3a9-e372-4ba7-85e1-f0839eb74e03",
   "metadata": {},
   "source": [
    "# ‚öΩ Player Re-Identification Assignment\n",
    "\n",
    "## üéØ Problem Statement\n",
    "Detect and consistently track each player in a soccer video using computer vision.\n",
    "\n",
    "## ‚úÖ Analytical Goal\n",
    "- Use a pre-trained YOLOv11 model to detect players.\n",
    "- Track each player across frames with consistent IDs.\n",
    "- Output a video with visible player IDs.\n",
    "\n",
    "## üìÅ Input Details\n",
    "- Video: `15sec_input_720p.mp4`\n",
    "- YOLOv11 Weights: `best.pt` (custom weights provided)\n",
    "\n",
    "## üóÇÔ∏è Output Deliverables\n",
    "- Python code / notebook\n",
    "- Output video with IDs\n",
    "- README.md & short report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0acac5-fed5-403e-bedd-f720f3a48f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Poornima Kc\\anaconda3\\envs\\player_reid\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Verify Conda Environment\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110dc9d-4fde-4f62-8962-958a9590d083",
   "metadata": {},
   "source": [
    "### ‚úÖ 1. Check Python executable\n",
    "\n",
    "Confirmed that Jupyter Notebook is running in the correct Conda environment `player_reid`.\n",
    "\n",
    "**Output:**  \n",
    "`C:\\Users\\Poornima Kc\\anaconda3\\envs\\player_reid\\python.exe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901796b-c467-48b0-af70-6cbb77a136c8",
   "metadata": {},
   "source": [
    "### ‚úÖ 2. Video Open Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3229bb-ca1b-420a-a51c-28b216fad467",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"15sec_input_720p.mp4\")\n",
    "ret, frame = video.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbb387-d697-411a-be0a-d9f6702213a4",
   "metadata": {},
   "source": [
    "### ‚úÖ 3. Read & Inspect Frame\n",
    "\n",
    "Read first frame from video and displayed pixel data to confirm valid read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a26c19-e38b-4cb1-8d54-ad47ebe340cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened: True\n",
      "ret: True\n",
      "frame: [[[ 95  78 104]\n",
      "  [ 95  78 104]\n",
      "  [ 94  77 103]\n",
      "  ...\n",
      "  [142 161 186]\n",
      "  [150 169 194]\n",
      "  [154 173 198]]\n",
      "\n",
      " [[137 120 146]\n",
      "  [137 120 146]\n",
      "  [137 120 146]\n",
      "  ...\n",
      "  [179 198 223]\n",
      "  [188 207 232]\n",
      "  [191 210 235]]\n",
      "\n",
      " [[201 184 210]\n",
      "  [201 184 210]\n",
      "  [202 185 211]\n",
      "  ...\n",
      "  [182 201 226]\n",
      "  [190 209 234]\n",
      "  [193 212 237]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[125 135 147]\n",
      "  [125 135 147]\n",
      "  [125 135 147]\n",
      "  ...\n",
      "  [ 67 101  94]\n",
      "  [ 67 101  94]\n",
      "  [ 67 101  94]]\n",
      "\n",
      " [[123 133 145]\n",
      "  [123 133 145]\n",
      "  [123 133 145]\n",
      "  ...\n",
      "  [ 75 109 102]\n",
      "  [ 75 109 102]\n",
      "  [ 75 109 102]]\n",
      "\n",
      " [[119 129 141]\n",
      "  [119 129 141]\n",
      "  [119 129 141]\n",
      "  ...\n",
      "  [ 81 115 108]\n",
      "  [ 81 115 108]\n",
      "  [ 81 115 108]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Video opened:\", video.isOpened())\n",
    "print(\"ret:\", ret)\n",
    "print(\"frame:\", frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd792e3-53b2-4609-96b1-1c26869dccf4",
   "metadata": {},
   "source": [
    "### ‚úÖ 4. Save First Frame\n",
    "\n",
    "Extracted and saved the first frame as `sample_frame.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc214f5-059a-4665-b9f6-f83d0256d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret: True\n",
      "Saved as sample_frame.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(\"15sec_input_720p.mp4\")\n",
    "ret, frame = video.read()\n",
    "print(\"ret:\", ret)\n",
    "if ret:\n",
    "    cv2.imwrite(\"sample_frame.jpg\", frame)\n",
    "    print(\"Saved as sample_frame.jpg\")\n",
    "else:\n",
    "    print(\"Could not read frame.\")\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b525d-79f2-4d5b-8770-ade8f8851df4",
   "metadata": {},
   "source": [
    "### ‚úÖ 5. Save New Frame at Position 50\n",
    "\n",
    "Advanced to frame 50 to check detection performance on a different scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc7e2f55-f20e-4d13-a171-60f754e840c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(\"15sec_input_720p.mp4\")\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 50)  \n",
    "ret, frame = video.read()\n",
    "if ret:\n",
    "    cv2.imwrite(\"sample_frame.jpg\", frame)\n",
    "    print(\"Saved new frame\")\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08096c3-f560-4a76-8f97-801fc42a2072",
   "metadata": {},
   "source": [
    "### ‚úÖ 6. YOLOv11 Detection Test\n",
    "\n",
    "Loaded YOLOv11 model weights and ran detection on `sample_frame.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faa20d0b-088c-48eb-b55a-cacca98da028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Poornima Kc\\Downloads\\sample_frame.jpg: 384x640 16 players, 2 referees, 1441.6ms\n",
      "Speed: 2.9ms preprocess, 1441.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"best.pt\")  \n",
    "\n",
    "results = model(\"sample_frame.jpg\", show=True)\n",
    "\n",
    "for r in results:\n",
    "    r.save(filename=\"detected_output.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87fee3d-18c1-41f4-beff-ae946f2886fe",
   "metadata": {},
   "source": [
    "**Output:**  \n",
    "- 16 players and 2 referees detected.\n",
    "- Bounding boxes displayed correctly.\n",
    "- Saved detection result as `detected_output.jpg`.\n",
    "\n",
    "This confirms the detection pipeline works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1557c9-ea41-43e8-a13f-756338dba975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206644c-b72a-4989-b3a3-86dcb7e048e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16612d9-1437-4163-984a-dea098ee7bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e2603-961a-4b90-a21b-04d29d3ec9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0221d48-c9b5-4503-8694-84dd2b136032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
